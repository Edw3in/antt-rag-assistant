import sys, pathlib
from typing import List

# Docling (carrega mÃºltiplos formatos)
from langchain_docling import DoclingLoader

# Split por tokens para respeitar limites do embedding
from langchain_text_splitters import TokenTextSplitter

# Vector store
from langchain_community.vectorstores import Chroma
from langchain_community.vectorstores.utils import filter_complex_metadata

# Embeddings (pacote novo)
from langchain_huggingface import HuggingFaceEmbeddings

PERSIST_DIR = "./chroma_db"
EMBED_MODEL = "BAAI/bge-m3"
ALLOWED_EXT = {".pdf", ".docx", ".pptx", ".xlsx", ".html", ".htm", ".png", ".jpg", ".jpeg"}

def collect_paths(args: List[str]) -> list[str]:
    files: list[str] = []
    for a in args:
        p = pathlib.Path(a).resolve()
        if p.is_dir():
            for f in p.rglob("*"):
                if f.is_file() and f.suffix.lower() in ALLOWED_EXT:
                    files.append(str(f))
        elif p.is_file() and p.suffix.lower() in ALLOWED_EXT:
            files.append(str(p))
        else:
            print(f"[AVISO] Ignorado (nÃ£o existe/sem suporte): {p}")
    return sorted(set(files))

if __name__ == "__main__":
    inputs = sys.argv[1:]
    if not inputs:
        print("âŒ VocÃª precisa informar arquivos/pastas. Ex.:")
        print("   python ingest.py .\\docs")
        sys.exit(1)

    print("ğŸ”„ Iniciando processamento...\n")

    file_paths = collect_paths(inputs)
    if not file_paths:
        print("âŒ Nenhum arquivo suportado encontrado.")
        sys.exit(1)

    print("ğŸ“„ Lendo e convertendo documentos...")

    docs = []
    for fp in file_paths:
        print(f"   â†’ Convertendo: {fp}")
        loader = DoclingLoader(file_path=fp)
        docs.extend(loader.load())

    print(f"âœ… {len(docs)} documento(s) carregado(s)\n")

    print("âœ‚ï¸  Dividindo em pedaÃ§os (por tokens)...")
    splitter = TokenTextSplitter(chunk_size=350, chunk_overlap=40)  # evita ultrapassar 512 tokens
    splits = splitter.split_documents(docs)
    splits = filter_complex_metadata(splits)
    print(f"âœ… {len(splits)} pedaÃ§o(s) criado(s)\n")

    print("ğŸ§  Criando embeddings (GPU se disponÃ­vel)...")
    emb = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL,
        # normalizaÃ§Ã£o Ã© recomendada no bge-m3
        encode_kwargs={"normalize_embeddings": True},
    )

    print("ğŸ’¾ Salvando no banco vetorial (Chroma)...")
    db = Chroma.from_documents(splits, emb, persist_directory=PERSIST_DIR)
    # Chroma >0.4 persiste automaticamente; nÃ£o precisa db.persist()
    print(f"\nâœ… CONCLUÃDO! Base salva em: {PERSIST_DIR}")
